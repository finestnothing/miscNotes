{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fdd56d-bcd3-4ba3-b077-8cfb603d97b7",
   "metadata": {},
   "source": [
    "# Traffic Light Identification and Classification\n",
    "Senior Project\n",
    "Team PineApple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45543b33-4f6d-4a36-a5de-a8872b559625",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cd241-4e8f-4a8d-aadd-1d248793cc6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c5018-d817-4489-ba20-7ed0d1030175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Time loaded\")\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "print(\"Pandas loaded\")\n",
    "import numpy as np # linear algebra\n",
    "print(\"Numpy loaded\")\n",
    "import yaml # read yaml file\n",
    "print(\"Yaml loaded\")\n",
    "import os # For file path\n",
    "print(\"Os loaded\")\n",
    "import cv2 # For image processing\n",
    "print(\"OpenCV loaded\")\n",
    "import sklearn as sk # For machine learning\n",
    "print(\"Sklearn loaded\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Matplotlib loaded\")\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow loaded\")\n",
    "from shutil import copyfile\n",
    "print(\"Shutil loaded\")\n",
    "\n",
    "import torch # For neural network\n",
    "print(\"Torch loaded\")\n",
    "import PIL\n",
    "print(\"PIL loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a8df6-a1de-4e74-b24c-f03897529527",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Data available at https://hci.iwr.uni-heidelberg.de/content/bosch-small-traffic-lights-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ff427-257f-4bc6-abdf-1c68071d85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9bf80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key = yaml.load(open(train_file_path), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotatePicture(dictEntry):\n",
    "    img = cv2.imread(dictEntry['path']).copy()\n",
    "    for i in dictEntry['boxes']: \n",
    "        startPoint = (int(i['x_min']), int(i['y_min']))\n",
    "        endPoint = (int(i['x_max']), int(i['y_max']))\n",
    "        cv2.rectangle(img, startPoint, endPoint, (0,255,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to show test output\n",
    "img = annotatePicture(train_key[23])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a45103",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2448b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying encoding labels\n",
    "labels = []\n",
    "for i in range(len(train_key)):\n",
    "    for boxes in train_key[i]['boxes']:\n",
    "                if(boxes['label'] not in labels):\n",
    "                    labels.append(boxes['label'])\n",
    "labelDict = {}\n",
    "for i in labels:\n",
    "    labelDict[i] = labels.index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAnnotations(train_key, labelDict):\n",
    "    # For all images\n",
    "    # for i in range(len(train_key)):\n",
    "    for i in range(30):\n",
    "        filePath = train_key[i]['path']\n",
    "        indexOfName = filePath.rfind('/') + 1 # Get index of last '/'\n",
    "        annotationPath = filePath[indexOfName:].replace(\".png\", \".txt\") # Get shortened name of file\n",
    "        copyfile(filePath, \"./dataset/train/\" + annotationPath.replace(\".txt\", \".png\")) # Copy img to new location\n",
    "        \n",
    "        f = open(\"./dataset/train/\" + annotationPath, 'w') # .txt annotation file to make\n",
    "        f.truncate(0)\n",
    "        img_height, img_width = cv2.imread(filePath).shape[:2]\n",
    "        # For all boxes\n",
    "        for boxes in train_key[i]['boxes']:\n",
    "            xmin = int(boxes['x_min'])\n",
    "            ymin = int(boxes['y_min'])\n",
    "            xmax = int(boxes['x_max'])\n",
    "            ymax = int(boxes['y_max'])\n",
    "            avg_x = (xmin + xmax) / 2\n",
    "            avg_y = (ymin + ymax) / 2\n",
    "            yolo_width = (xmax - avg_x) / img_width\n",
    "            yolo_height = (ymax - avg_y) / img_height\n",
    "            yolo_x = avg_x / img_width\n",
    "            yolo_y = 1 - (avg_y / img_height)\n",
    "            yolo_label = labelDict[boxes['label']]\n",
    "            f.write(str(yolo_label) + \" \" + str(yolo_x) + \" \" + str(yolo_y) + \" \" + str(yolo_width) + \" \" + str(yolo_height) + \"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "makeAnnotations(train_key, labelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeConfig(path, train, val, test, labelDict):\n",
    "    f = open(\"config.yaml\", 'w')\n",
    "    f.truncate(0)\n",
    "    path = \"dataset/\"\n",
    "    f.write(\"path: \" + path + \"\\n\")\n",
    "    f.write(\"train: \" + train + \"/\\n\")\n",
    "    f.write(\"val: \" + val + \"/\\n\")\n",
    "    # f.write(\"train: \" + test + \"/\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"nc: \" + str(len(labelDict)) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"names: \" + str(labelDict.keys())[10:-1] + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6305683",
   "metadata": {},
   "outputs": [],
   "source": [
    "makeConfig(\"../dataset/\", \"train\", \"train\", \"test\", labelDict) #train and val are same folder for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0569616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isdir(\"yolov5\")):\n",
    "    os.popen(\"./scripts/importYolo.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = 720\n",
    "batch = 16\n",
    "epochs = 12\n",
    "configFile = \"config.yaml\"\n",
    "model = \"yolov5s.pt\"\n",
    "name = \"yolo_light_detection\"\n",
    "\n",
    "!python yolov5/train.py --img $imgs --batch $batch --epoch $epochs --data $configFile --weights $model --name $name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/detect.py --source ./dataset/train/ --weights yolov5/runs/train/yolo_light_detection5/weights/best.pt --conf 0.25 --name yolo_light_detection_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
