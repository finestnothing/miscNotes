{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 180  Intelligent Systems (Fall 2021)\n",
    "\n",
    "#### Dr. Haiquan Chen, Dept of Computer Scicence\n",
    "\n",
    "#### California State University, Sacramento\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10: Regularization and Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Produce final feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 and L2 regularization techniques used in linear regression\n",
    "\n",
    "L1 and L2 regularization are two common regularization techniques.\n",
    "\n",
    "We are going to look at linear regression to see how L1 and L2 regularization work.  The following code sets up the auto-mpg data for this purpose.\n",
    "\n",
    "https://www.kaggle.com/uciml/autompg-dataset/home\n",
    "\n",
    "The labeling on the origin column is 1 for domestic, 2 for Europe and 3 for Asia\n",
    "\n",
    "They are used to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac catalina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc ambassador dpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge challenger se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth 'cuda 340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet monte carlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick estate wagon (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc hornet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford maverick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>datsun pl510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen 1131 deluxe sedan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin                          name  \n",
       "0        1     chevrolet chevelle malibu  \n",
       "1        1             buick skylark 320  \n",
       "2        1            plymouth satellite  \n",
       "3        1                 amc rebel sst  \n",
       "4        1                   ford torino  \n",
       "5        1              ford galaxie 500  \n",
       "6        1              chevrolet impala  \n",
       "7        1             plymouth fury iii  \n",
       "8        1              pontiac catalina  \n",
       "9        1            amc ambassador dpl  \n",
       "10       1           dodge challenger se  \n",
       "11       1            plymouth 'cuda 340  \n",
       "12       1         chevrolet monte carlo  \n",
       "13       1       buick estate wagon (sw)  \n",
       "14       3         toyota corona mark ii  \n",
       "15       1               plymouth duster  \n",
       "16       1                    amc hornet  \n",
       "17       1                 ford maverick  \n",
       "18       3                  datsun pl510  \n",
       "19       2  volkswagen 1131 deluxe sedan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369908/1183005336.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop('name', 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin-1</th>\n",
       "      <th>origin-2</th>\n",
       "      <th>origin-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin-1  origin-2  origin-3  \n",
       "0          1         0         0  \n",
       "1          1         0         0  \n",
       "2          1         0         0  \n",
       "3          1         0         0  \n",
       "4          1         0         0  \n",
       "5          1         0         0  \n",
       "6          1         0         0  \n",
       "7          1         0         0  \n",
       "8          1         0         0  \n",
       "9          1         0         0  \n",
       "10         1         0         0  \n",
       "11         1         0         0  \n",
       "12         1         0         0  \n",
       "13         1         0         0  \n",
       "14         0         0         1  \n",
       "15         1         0         0  \n",
       "16         1         0         0  \n",
       "17         1         0         0  \n",
       "18         0         0         1  \n",
       "19         0         1         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name', 1, inplace=True)\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode to a 2D matrix for training\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Linear Regression\n",
    "\n",
    "To understand L1/L2 regularization, it is good to start with linear regression.  L1/L2 were first introduced for [linear regression](https://en.wikipedia.org/wiki/Linear_regression).  They can also be used for neural networks.  \n",
    "\n",
    "The following code uses linear regression to fit the auto-mpg data set.  The RMSE reported will not be as good as a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.937157392501831\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin-1', 'origin-2', 'origin-3']\n"
     ]
    }
   ],
   "source": [
    "names = list(df.columns.values)\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41654855,  0.0244562 , -0.00778463, -0.00747326,  0.13812254,\n",
       "        0.80127406, -1.4483734 ,  0.8185649 ,  0.62980866], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_\n",
    "# Useful for telling which features are important and which are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.257532"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a regression\n",
    "\n",
    "%matplotlib inline    \n",
    "from IPython.display import display   \n",
    "\n",
    "def report_coef(names,coef,intercept):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    print(\"Intercept: {}\".format(intercept))\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.448373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.416549</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.007785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007473</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.024456</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138123</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.629809</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.801274</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.818565</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.448373     False\n",
       "cylinders    -0.416549     False\n",
       "horsepower   -0.007785     False\n",
       "weight       -0.007473     False\n",
       "displacement  0.024456      True\n",
       "acceleration  0.138123      True\n",
       "origin-3      0.629809      True\n",
       "year          0.801274      True\n",
       "origin-2      0.818565      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.257532119750977\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 (Lasso) Regularization\n",
    "\n",
    "L1 Regularization, also called LASSO (Least Absolute Shrinkage and Selection Operator) should be used to create sparsity in the neural network. \n",
    "\n",
    "### L1 algorithm will push many weight connections to near 0.  \n",
    "\n",
    "When a weight is near 0, the program drops it from the network.  Dropping weighted connections will create a sparse neural network.\n",
    "\n",
    "### The lower weight values will typically lead to less overfitting.\n",
    "\n",
    "\n",
    "### Minimization objective = SSE (Sum of Squared Error) + $\\alpha$ * (Sum of Absolute Value of Coefficients)\n",
    "\n",
    "When $\\alpha$ is 0, Lasso regression produces the same coefficients as a linear regression. When $\\alpha$ is very very large, all coefficients are zero.\n",
    "\n",
    "The following code demonstrates lasso regression.  Notice the effect of the coefficients compared to the previous section that used linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.0409061908721924\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.264469</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.002797</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.013005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.113762</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.787195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.264469     False\n",
       "weight       -0.007458     False\n",
       "horsepower   -0.002797     False\n",
       "cylinders    -0.000000      True\n",
       "origin-2      0.000000      True\n",
       "origin-3      0.000000      True\n",
       "displacement  0.013005      True\n",
       "acceleration  0.113762      True\n",
       "year          0.787195      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -17.271318435668945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit/train LASSO\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:  If your data set has a large number of input features that may not be needed, L1 regularization can help to detect and ignore unnecessary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 (Ridge) Regularization\n",
    "\n",
    "Use Ridge/L2 regularization when you prefer low weight values.  ***The lower weight values will typically lead to less overfitting.*** \n",
    "\n",
    "\n",
    "### Minimization objective = SSE (Sum of Squared Error) + $\\alpha$ * (Sum of Square of Coefficients)\n",
    "\n",
    "When $\\alpha$ is 0, L2 regression produces the same coefficients as a linear regression. When $\\alpha$ is very very large, all coefficients are zero.\n",
    "\n",
    "### L1 will force the weights into a pattern similar to a laplace distribution; the L2 will force the weights into a pattern similar to a Gaussian distribution***, as demonstrated the following:\n",
    "\n",
    "![L1 vs L2](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_l1_l2.png \"L1 vs L2\")\n",
    "\n",
    "\n",
    "The following code uses L2 with linear regression (Ridge regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.937575578689575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=3.88494e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-1.444143</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.415849</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.007759</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007473</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.024423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.138105</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.630158</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.801221</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.818294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -1.444143     False\n",
       "cylinders    -0.415849     False\n",
       "horsepower   -0.007759     False\n",
       "weight       -0.007473     False\n",
       "displacement  0.024423      True\n",
       "acceleration  0.138105      True\n",
       "origin-3      0.630158      True\n",
       "year          0.801221      True\n",
       "origin-2      0.818294      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -18.256078720092773\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAD4CAYAAABIQCkOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbA0lEQVR4nO3de5hddX3v8feHQI0Q5GIiRQRHIJoDKinZIMilqDl4KWIo8CBaK9eoT71ywnnso9DCkXrrqfXYIo1RA+dYtGgiSKncNAQCkcyE3BDjBUgrD+qgSAmWgOFz/ti/MZtx7rNn7zV7Pq/nmWevvdZv/dZ3r9mZT35rr72WbBMREVElO7W7gIiIiP4SThERUTkJp4iIqJyEU0REVE7CKSIiKmfndhfQKWbOnOmurq52lxERMWn09PQ8YnvWQMsSTk3S1dVFd3d3u8uIiJg0JG0ZbFkO60VEROUknCIionISThERUTkJp4iIqJycEBERlSC1u4IYi4m6PGtGThERUTkJp4iIqJxJG06SbpC05zBtLpU0f5T9fkXSZkmbJH1J0i7jKjQiIkZt0oWT6nay/Sbbvx6qre2Lbd8yyk18BZgDvAJ4LnDe2CqNiIixqmQ4SbqgjFw2SfqgpK4ymrkK2ATsL+lBSTNL+4vK8jskXS1pUZm/VNJpZfpBSZdIWitpo6Q5A23b9g0ugLuBF7XmVUdERJ/KhZOkecDZwKuAo4Dzgb2A2cDltg+1vaWh/RHAqcBhwBuB2hDdP2L7cODzwKJh6tgFeAfw7SHaLJTULam7t7d3JC8vIiJGoHLhBBwLLLf9hO2twDLgOGCL7dUDtD8GuNb2k7YfB741RN/LymMP0DVMHZcDK23fPlgD24tt12zXZs0a8NqFERExBlUMp8E80YQ+tpXH7ZTveEm6UdI6SUv6Gkn6K2AWcEETthkREaNUxXC6HVggaVdJuwGnlHmDWQW8WdJ0STOAk0azMduvtz3X9nkAks4DXg+cafuZsb2EiIgYj8pdIcL2WklLqZ+MALAEeHSI9mskXQdsAH4ObAQeG0cJVwBbgLtU/8r6MtuXjqO/iIgYJXmirj3RQpJm2N4qaVdgJbDQ9tpW1lCr1Zz7OUWMXS5fNDmNJ0Ik9dge8CS2yo2cxmixpEOA6cCVrQ6miBi/Dvh/cjRRR4ST7be1u4aIiGieKp4QERERU1zCKSIiKifhFBERlZNwioiIykk4RURE5SScIiKichJOERFROQmniIionIRTRERUTsIpIiIqJ+EUERGV0xHX1ouIyS9XJZ9cJvpCvRk5RURE5SScIiKichJOIyRpWrtriIiYKjoynCRdKumDDc8vk/QBSRdKWiNpg6RLGpZ/U1KPpHslLWyYv1XS/5a0Hji6ta8iImLq6shwAr4E/DmApJ2AtwI/A2YDRwJzgXmSji/tz7E9D6gB75f0/DJ/N+B7tg+zfUcL64+ImNI68mw92w9K+qWkPwL2Ae4BjgBOLNMAM6iH1UrqgXRKmb9/mf9LYDvwjcG2U0ZZCwEOOOCACXglERFTU0eGU7EEOAv4Q+ojqdcBH7f9T42NJJ0AzAeOtv0bSSuA6WXxk7a3D7YB24uBxQC1Wm2CT6yMiJg6OvWwHsBy4A3UR0w3lp9zJM0AkLSfpBcAewCPlmCaAxzVroIjIqKuY0dOtp+S9F3g12X0c5Ok/wbcpfq3/bYCfwZ8G3i3pPuAzcDqdtUcERF1HRtO5USIo4DT++bZ/izw2QGav3GgPmzPmJjqIiJiKB15WE/SIcCPgVtt/6jd9URExOh05MjJ9veBA9tdR0SM3ERfqy0ml44cOUVExOSWcIqIiMpJOEVEROUknCIionISThERUTkJp4iIqJyEU0REVE7CKSIiKifhFBERlZNwioiIykk4RURE5XTktfUiYvKp38kmmmkyX68wI6eIiKichFNERFTOpA4nSTdI2nOYNpdKmj/Kfr8oab2kDZK+3ndr94iIaI1JGU6q28n2m2z/eqi2ti+2fcsoN/Eh24fZfiXw78B7x1prRESMXmXDSdIFkjaVnw9K6pK0WdJVwCZgf0kPSppZ2l9Ult8h6WpJi8r8pZJOK9MPSrpE0lpJGyXNGWjbtv+ztBfwXGASf6wYETH5VDKcJM0DzgZeBRwFnA/sBcwGLrd9qO0tDe2PAE4FDgPeCNSG6P4R24cDnwcWDVHDl4GfAXOAzw3SZqGkbkndvb29o3iFERExlEqGE3AssNz2E7a3AsuA44AttlcP0P4Y4FrbT9p+HPjWEH0vK489QNdgjWyfDbwQuA84Y5A2i23XbNdmzZo13GuKiIgRqmo4DeaJJvSxrTxup3zPS9KNktZJWtLY0PZ24KvUR2UREdEiVQ2n24EFknaVtBtwSpk3mFXAmyVNL2fWnTSajdl+ve25ts8rJ1scDL/7zOlk4AdjexkRETEWlbxChO21kpYCd5dZS4BHh2i/RtJ1wAbg58BG4LExbl7AlZKeV6bXA+8ZY18RETEG8mS+vkUDSTNsb5W0K7ASWGh7bau2X6vV3N3d3arNRXScXL6o+ar+511Sj+0BT2Cr5MhpjBZLOgSYDlzZymCKiPGr+h/SaK2OCSfbb2t3DRER0RxVPSEiIiKmsIRTRERUTsIpIiIqJ+EUERGVk3CKiIjKSThFRETlJJwiIqJyEk4REVE5CaeIiKichFNERFROx1y+KCImt2Ze+DXX6Zv8MnKKiIjKSThFRETlVDKcJK2QNOA9PsbQ14JyK42+55dKmt+MviMiYmJUMpxGS9K0IRYvAH4XTrYvtn3LhBcVERFjNq5wkvRNST2S7pW0sMx7g6S1ktZLurXMmyHpy5I2Stog6dQy/0RJd5X210iaMcA2Bmwj6UFJn5S0Fjhd0vmS1pTtfkPSrpJeDZwMfFrSOkkHSVoq6bTSx+sk3VPq+pKk5zT0fUnZ5kZJc8aznyIiYnTGO3I6x/Y8oAa8X9I+wBeAU20fBpxe2l0EPGb7FbZfCXxH0kzgo8B824cD3cAFjZ2PoM0vbR9u+6vAMttHlO3eB5xr+07gOuBC23Nt/6Sh7+nAUuAM26+gfubiexr6fqRs8/PAooFevKSFkroldff29o5uz0VExKDGG07vl7QeWA3sDywEVtp+AMD2r0q7+cA/9q1k+1HgKOqH21ZJWge8E3hxv/6Ha/O1humXS7pd0kbg7cChw9T+MuAB2z8sz68Ejm9Yvqw89gBdA3Vge7Htmu3arFmzhtlcRESM1Ji/5yTpBOqhc7Tt30haAawDRnoITMDNts8cR5snGqaXAgtsr5d0FnDCCOsYzLbyuJ18HywioqXGM3LaA3i0BNMc6qOc6cDxkl4CIGnv0vZm4C/6VpS0F/XR1jGSDi7zdpP00n7bGEmbPrsDD0vahfrIqc/jZVl/m4Guvr6BdwC3jeB1R0TEBBtPOH0b2FnSfcAnqAdJL/VDe8vK4b6+w24fA/aStKnMf43tXuAs4GpJG4C76DfqGkmbBhcB3wNWAT9omP9V4MJy4sNBDX0/CZwNXFMOBT4DXDGWHREREc0l5zofTVGr1dzd3d3uMiImrVy+aOqR1GN7wO+05rOUiKiEBEo06ogv4UZERGdJOEVEROUknCIionISThERUTkJp4iIqJyEU0REVE7CKSIiKifhFBERlZNwioiIykk4RURE5SScIiKicnJtvYiohMYLv+Y6e5GRU0REVE7CKSIiKmfUh/Uk/TWwFXgesNL2LaNc/wRgke2TRrvtVpO0APih7e+3u5aIiKlkzCMn2xePNpgmoQXAIe0uIiJiqhlROEn6iKQfSroDeFmZt1TSaWX6E5K+L2mDpL9tWH6FpO6y7u+NlCQdKemucgv1OyX19T1N0t+W27pvkPS+Mn+epNsk9Ui6UdK+Zf4KSZ8p27pP0hGSlkn6kaSPNWzvzyTdLWmdpH+SNK3M3yrpMknrJa2WtI+kVwMnA58u7Q/qX39EREyMYQ/rSZoHvBWYW9qvBXoalj8fOAWYY9uS9mxYvQs4EjgI+K6kg/t1/wPgONu/lTQf+BvgVGBhWXduWba3pF2AzwFvsd0r6QzgMuCc0tdTtmuSPgBcC8wDfgX8RNJngBcAZwDH2H5a0uXA24GrgN2A1bY/IulTwPm2PybpOuB6218fZN8sLLVywAEHDLcrIyJihEbymdNxwHLbvwEof7AbPQY8CXxR0vXA9Q3L/sX2M8CPJN0PzOm37h7AlZJmAwZ2KfPnA1fY/i2A7V9JejnwcuBm1c85nQY83NBXX10bgXttP1zqvR/YHziWemCtKes/F/hFWeephrp7gP8+gv2C7cXAYoBarZaTXyMimmTc33MqI5sjgdcBpwHvBV7bt7h/837P/xfwXdunSOoCVgyxKVEPnaMHWb6tPD7TMN33fOey/pW2/3KAdZ+2f/fNiu3k+18REW01ks+cVgILJD1X0u7AmxsXSpoB7GH7BuBDwGENi0+XtFP5vOZAYHO/vvcAHirTZzXMvxl4l6Sdyzb2LuvOknR0mbeLpENHUH+fW4HTJL2gr09JLx5mnceB3UexjYiIaIJhw8n2WuBrwHrg34A1/ZrsDlwvaQNwB3BBw7J/B+4u673b9pP91v0U8HFJ9/Ds0cqSsu4GSeuBt9l+ivrI7JNl3jrg1SN5keV1fB/4KHBTqfVmYN9hVvsqcGE5YSMnREREtIg8QdcJkbSUIU4m6DS1Ws3d3d3tLiNi0srli6YeST22awMty2crEVEJCaRoNGHhZPusieo7IiI6W66tFxERlZNwioiIykk4RURE5SScIiKichJOERFROQmniIionIRTRERUTsIpIiIqJ+EUERGVk3CKiIjKSThFRPs1XvU1goRTRERUUMIpIiIqp6PDSdISSYcM02appNMGmN8l6W0TV11ERAymo8PJ9nnlDrhj0QUknCIi2mBShJOkCyW9v0x/RtJ3yvRrJX1F0omS7pK0VtI1kmaU5Ssk1cr0uZJ+KOluSV+Q9A8Nmzhe0p2S7m8YRX0COE7SOkkfauHLjYiY8iZFOAG3A8eV6RowQ9IuZd4G4KPAfNuHA93ABY0rS3ohcBFwFHAMMKdf//sCxwInUQ8lgA8Dt9uea/szAxUlaaGkbkndvb2943yJERHRZ7KEUw8wT9LzgG3AXdRD6jjgv4BDgFWS1gHvBF7cb/0jgdts/8r208A1/ZZ/0/Yz5RDgPiMtyvZi2zXbtVmzZo3ldUVExAAm7DbtzWT7aUkPAGcBd1IfLb0GOBh4ALjZ9pnj2MS2hul84SIios0my8gJ6of2FgEry/S7gXuA1cAxkg4GkLSbpJf2W3cN8MeS9pK0M3DqCLb3OLB7s4qPiIiRm2zhtC9wl+2fA09S/0yol/qI6mpJG6gf8nvWZ0q2HwL+BrgbWAU8CDw2zPY2ANslrc8JERERrSXb7a6hJSTNsL21jJyWA1+yvbxZ/ddqNXd3dzeru4ipRYIp8rcodpDUY7s20LLJNHIar78uJ0xsov451TfbWk1E7JBgin4mxQkRzWB7UbtriIiIkZlKI6eIiJgkEk4REVE5CaeIiKichFNERFROwikiIion4RQREZWTcIqIiMpJOEVEROUknCIionISThERUTkJp4hoP+U2avFsCaeIiKichFNERFROU8JJUpekTc3oKyIiou0jp3Lzv8qbLHVGRHSCZobTNElfkHSvpJskPVfSXEmrJW2QtFzSXgCSVkj6e0ndwAcknS5pU7kl+srSZpqkT0taU9Z/V5l/gqSVkv5V0mZJV0jaqSw7U9LG0tcny7zTJf1dmf6ApPvL9IGSVpXpeZJuk9Qj6UZJ+w5UZxP3VUREDKGZo4HZwJm2z5f0L8CpwP8E3mf7NkmXAn8FfLC0/4O+2/NK2gi83vZDkvYsy88FHrN9hKTnAKsk3VSWHQkcAmwBvg38qaQ7gU8C84BHgZskLQBuL3UAHAf8UtJ+ZXqlpF2AzwFvsd0r6QzgMuCc/nX2J2khsBDggAMOGNNOi4iI39fMcHrA9roy3QMcBOxp+7Yy70rgmob2X2uYXgUsLaG2rMw7EXilpNPK8z2oB+BTwN22+0ZAVwPHAk8DK2z3lvlfAY63/U1JMyTtDuwP/DNwPPVwWga8DHg5cLPqp7NOAx4epM5nsb0YWAxQq9Vyn+mIiCZpZjhta5jeDuw5TPsn+iZsv1vSq4A/AXokzQNEfdR1Y+NKkk4A+gfBcMFwJ3A2sJn6SOoc4GjgfwAHAPfaPnq4OiMiojUm8oSIx4BHJR1Xnr8DuG2ghpIOsv092xcDvdRHODcC7ymH3ZD0Ukm7lVWOlPSS8lnTGcAdwN3AH0uaKWkacGbD9m4HFgErgXuA1wDbbD9GPbBmSTq6bGcXSYc2bzdERMRoTfQZaO8ErpC0K3A/9dHLQD4taTb10dKtwHpgA9AFrFX9eFsvsKC0XwP8A3Aw8F1gue1nJH24PBfwr7avLe1vpx54K21vl/QfwA8AbD9VDh3+H0l7UN8nfw/c25Q9EBERoyZ7cn1UUg7rLbJ9UptLeZZarebu7u52lxExOUkwyf4WxfhJ6hnshLO2f88pIiLBFP1Nui+W2l4BrGhzGRERMYEycoqIiMpJOEVEROUknCIionISThERUTkJp4iIqJyEU0REVE7CKSIiKifhFBERlZNwioiIykk4RURE5SScIiKicibdtfUipqz6nZo7Vy7+Gg0ycoqIiMqZFOEkaWm5ISCSlkg6ZJTrb52YyiIiYiJMusN6ts+byP7LXXdl+5mJ3E5ERAyurSMnSX8uaYOk9ZKWS3pA0i5l2fManzess0JSrUxvlXRZWX+1pH3K/JdIukvSRkkf67f+hZLWlO1eUuZ1Sdos6SpgE7B/Ga1tKn18qBX7IyIi6toWTpIOBT4KvNb2YcC51G8i+CelyVuBZbafHqKb3YDVZf2VwPll/meBz9t+BfBwwzZPBGYDRwJzgXmSji+LZwOX2z4UmAnsZ/vlpY8vj/PlRkTEKLRz5PRa4BrbjwDY/hWwBDi7LD+b4UPhKeD6Mt0DdJXpY4Cry/T/bWh/Yvm5B1gLzKEeSgBbbK8u0/cDB0r6nKQ3AP850MYlLZTULam7t7d3mFIjImKkKnVChO1VQJekE4BptjcNs8rT9u/OP93Osz9DG+i8VAEftz23/Bxs+4tl2RMNdTwKHEZ9JPdu6qE5UL2Lbdds12bNmjVMqRERMVLtDKfvAKdLej6ApL3L/KuAf2Z8h9JWUT8sCPD2hvk3AudImlG2uZ+kF/RfWdJMYCfb36B+6PHwcdQSERGj1LZwsn0vcBlwm6T1wN+VRV8B9mLHYbmx+ADwF5I2Avs1bPMm6sF3V1n2dWD3AdbfD1ghaR3w/4C/HEctERExSnLFvpVdvs/0FtvvaHcto1Gr1dzd3d3uMqKT5QoR0WEk9diuDbSsUt9zkvQ54I3Am9pdS0REtE+lwsn2+9pdQ0RlZWQRU0ilztaLiIiAhFNERFRQwikiIion4RQREZWTcIqIiMpJOEVEROUknCIionISThERUTkJp4iIqJyEU0REVE7CKSIiKqdS19absjr9atMRI5FrB0aDjJwiIqJyEk4REVE5kzacJN0gac9h2lwqaf4o+32vpB9Lcrlde0REtNik+8xJkqjfwXfYGxLavngMm1gFXA+sGMO6ERHRBJUcOUm6QNKm8vNBSV2SNku6CtgE7C/pwb6RjaSLyvI7JF0taVGZv7Tc9p3S/hJJayVtlDRnoG3bvsf2gy16qRERMYDKhZOkecDZwKuAo4Dzgb2A2cDltg+1vaWh/RHAqcBh1G/xPuD96ItHbB8OfB5Y1IRaF0rqltTd29s73u4iIqKoXDgBxwLLbT9heyuwDDgO2GJ79QDtjwGutf2k7ceBbw3R97Ly2AN0jbdQ24tt12zXZs2aNd7uIiKiqGI4DeaJJvSxrTxup3zeJulGSeskLWlC/xER0QRVDKfbgQWSdpW0G3BKmTeYVcCbJU2XNAM4aTQbs/1623Ntnzf2kiMiopkqF0621wJLgbuB7wFLgEeHaL8GuA7YAPwbsBF4bKzbl/R+ST8FXgRsyIgqIqL15A64ZIikGba3StoVWAksLCHXMrVazd3d3WNbOZcvisjli6YgST22BzyJbdJ9z2kQiyUdAkwHrmx1MI1b/lFGRDxLR4ST7be1u4aIiGieyn3mFBERkXCKiIjKSThFRETlJJwiIqJyOuJU8iqQ1AtsGWTxTOCRFpZTddkfO2Rf7JB9scNU2Rcvtj3gtd8STi0gqXuwc/mnouyPHbIvdsi+2CH7Iof1IiKighJOERFROQmn1ljc7gIqJvtjh+yLHbIvdpjy+yKfOUVEROVk5BQREZWTcIqIiMpJOE0ASadLulfSM5IGPR1U0oOSNpY78Y7xfhvVN4r98QZJmyX9WNKHW1ljq0jaW9LNkn5UHvcapN328r5YJ+m6Vtc5kYb7PUt6jqSvleXfk9TVhjJbYgT74ixJvQ3vhSlzU9SE08TYBPwp9XtLDec15U68nfydhmH3h6RpwD8CbwQOAc4st0HpNB8GbrU9G7i1PB/If5X3xVzbJ7euvIk1wt/zucCjtg8GPgN8srVVtsYo3vNfa3gvTJmbnyacJoDt+2xvbncdVTHC/XEk8GPb99t+Cvgq8JaJr67l3gJcWaavBBa0r5S2GMnvuXEffR14ndSRd+ScKu/5MUk4tZeBmyT1SFrY7mLabD/gPxqe/7TM6zT72H64TP8M2GeQdtMldUtaLWlBa0priZH8nn/XxvZvgceA57ekutYa6Xv+VEkbJH1d0v6tKa39OuJmg+0g6RbgDwdY9BHb146wm2NtPyTpBcDNkn5geySHAiunSfujIwy1Lxqf2Lakwb7L8eLy3jgQ+I6kjbZ/0uxao/K+BVxte5ukd1EfUb62zTW1RMJpjGzPb0IfD5XHX0haTn2YPynDqQn74yGg8X+FLyrzJp2h9oWkn0va1/bDkvYFfjFIH33vjfslrQD+COiEcBrJ77mvzU8l7QzsAfyyNeW11LD7wnbj614CfKoFdVVCDuu1iaTdJO3eNw2cSP3EgalqDTBb0ksk/QHwVqCjzlIrrgPeWabfCfzeqFLSXpKeU6ZnAscA329ZhRNrJL/nxn10GvAdd+bVAobdF+U/MH1OBu5rYX3tZTs/Tf4BTqF+/Hgb8HPgxjL/hcANZfpAYH35uZf64a+2196u/VGevwn4IfURQkfuD+qfndwK/Ai4Bdi7zK8BS8r0q4GN5b2xETi33XU3eR/83u8ZuBQ4uUxPB64BfgzcDRzY7prbuC8+Xv4+rAe+C8xpd82t+snliyIionJyWC8iIion4RQREZWTcIqIiMpJOEVEROUknCIionISThERUTkJp4iIqJz/D92lWhQ3XxSgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create linear regression\n",
    "regressor = Ridge(alpha=0.1)\n",
    "\n",
    "# Fit/train Ridge\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet:   Linear regression with mixing L1 with L2.  \n",
    "    \n",
    "* $\\alpha$: Constant for penalty (regularization). \n",
    "    \n",
    "* l1_ratio : The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty.\n",
    "\n",
    "\n",
    "#### If you want the following:  a $*$ L1 + b $*$ L2,   set $\\alpha$ = a + b and l1_ratio = a / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.031985282897949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>origin-1</th>\n",
       "      <td>-0.938925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.257572</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.007462</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.002896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.017533</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.131321</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-3</th>\n",
       "      <td>0.369088</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-2</th>\n",
       "      <td>0.458725</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.788913</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef  positive\n",
       "origin-1     -0.938925     False\n",
       "cylinders    -0.257572     False\n",
       "weight       -0.007462     False\n",
       "horsepower   -0.002896     False\n",
       "displacement  0.017533      True\n",
       "acceleration  0.131321      True\n",
       "origin-3      0.369088      True\n",
       "origin-2      0.458725      True\n",
       "year          0.788913      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -17.480127334594727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create linear regression\n",
    "regressor = ElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    "\n",
    "# Fit/train ElasticNet\n",
    "regressor.fit(x_train,y_train)\n",
    "# Predict\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "names = list(df.columns.values)\n",
    "names.remove(\"mpg\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_,\n",
    "  regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can also apply such L1/L2 to get the feature importance for a classification problem.   This can be done by training a Logistic Regression model and observe the coefficient learned for each feature.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "\n",
    "#### The following is the sample code, which is just a little bit different than the way we did before for regression.  In this code, we remove y-intercept.   Note you should define x_train, y_train, x_test, y_test first to run the code.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_369908/2868801561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit/train linear regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create linear regression\n",
    "regressor = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=.1)\n",
    "\n",
    "# Fit/train linear regression\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to evaluate the coefficients of a classification\n",
    "\n",
    "def report_coef(names,coef):\n",
    "    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n",
    "    r = r.sort_values(by=['coef'])\n",
    "    display(r)\n",
    "    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_369908/3284732102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the plot for the importance of each feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your_output_feature_goes_here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m report_coef(\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# Create the plot for the importance of each feature\n",
    "\n",
    "names.remove(\"your_output_feature_goes_here\")\n",
    "\n",
    "report_coef(\n",
    "  names,\n",
    "  regressor.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  L1/L2 in TensorFlow?\n",
    "\n",
    "L1 and L2 regularization work by adding a weight penalty to the neural network training.  \n",
    "\n",
    "### This penalty push the connection weights to small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369908/244091398.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop('name',1,inplace=True)\n",
      "2021-10-04 11:05:28.366660: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-10-04 11:05:28.366753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alec-xps13): /proc/driver/nvidia/version does not exist\n",
      "2021-10-04 11:05:28.369845: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# TensorFlow with L1/L2 for Regression\n",
    "########################################\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "encode_text_dummy(df, 'origin')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can set three regularization params for Dense, Conv1D, Conv2D and Conv3D. \n",
    "\n",
    "keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "\n",
    "***kernel_regularizer***: Regularizer function applied to the kernel weights matrix. kernel regularizer will constantly decay the weights.\n",
    "\n",
    "***activity_regularizer***: Regularizer function applied to the output of the layer.  Activity regularizer will tend to make the output of the layer smaller.\n",
    "\n",
    "***bias_regularizer***: Regularizer function applied to the bias vector.\n",
    "\n",
    "https://keras.io/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 11:05:28.452580: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 - 0s - loss: 15422.7715 - val_loss: 10209.0342\n",
      "Epoch 2/100\n",
      "10/10 - 0s - loss: 5926.5015 - val_loss: 4126.1670\n",
      "Epoch 3/100\n",
      "10/10 - 0s - loss: 3761.9946 - val_loss: 2306.7207\n",
      "Epoch 4/100\n",
      "10/10 - 0s - loss: 2321.3237 - val_loss: 1899.0872\n",
      "Epoch 5/100\n",
      "10/10 - 0s - loss: 1636.8881 - val_loss: 1429.6461\n",
      "Epoch 6/100\n",
      "10/10 - 0s - loss: 1232.8116 - val_loss: 1028.6028\n",
      "Epoch 7/100\n",
      "10/10 - 0s - loss: 947.4642 - val_loss: 767.8094\n",
      "Epoch 8/100\n",
      "10/10 - 0s - loss: 729.9977 - val_loss: 588.6902\n",
      "Epoch 9/100\n",
      "10/10 - 0s - loss: 570.3315 - val_loss: 456.7469\n",
      "Epoch 10/100\n",
      "10/10 - 0s - loss: 456.1638 - val_loss: 361.1597\n",
      "Epoch 11/100\n",
      "10/10 - 0s - loss: 370.1435 - val_loss: 289.5148\n",
      "Epoch 12/100\n",
      "10/10 - 0s - loss: 296.2598 - val_loss: 203.9222\n",
      "Epoch 13/100\n",
      "10/10 - 0s - loss: 192.7819 - val_loss: 126.2074\n",
      "Epoch 14/100\n",
      "10/10 - 0s - loss: 145.4973 - val_loss: 105.6864\n",
      "Epoch 15/100\n",
      "10/10 - 0s - loss: 122.6487 - val_loss: 90.7810\n",
      "Epoch 16/100\n",
      "10/10 - 0s - loss: 108.8521 - val_loss: 79.5542\n",
      "Epoch 17/100\n",
      "10/10 - 0s - loss: 100.2056 - val_loss: 75.5862\n",
      "Epoch 18/100\n",
      "10/10 - 0s - loss: 93.8334 - val_loss: 71.8558\n",
      "Epoch 19/100\n",
      "10/10 - 0s - loss: 84.7869 - val_loss: 62.5552\n",
      "Epoch 20/100\n",
      "10/10 - 0s - loss: 77.2597 - val_loss: 60.6477\n",
      "Epoch 21/100\n",
      "10/10 - 0s - loss: 72.8573 - val_loss: 53.0735\n",
      "Epoch 22/100\n",
      "10/10 - 0s - loss: 67.7190 - val_loss: 51.2412\n",
      "Epoch 23/100\n",
      "10/10 - 0s - loss: 64.4633 - val_loss: 49.9389\n",
      "Epoch 24/100\n",
      "10/10 - 0s - loss: 62.7387 - val_loss: 48.3531\n",
      "Epoch 25/100\n",
      "10/10 - 0s - loss: 59.8623 - val_loss: 47.5548\n",
      "Epoch 26/100\n",
      "10/10 - 0s - loss: 59.5193 - val_loss: 47.3224\n",
      "Epoch 27/100\n",
      "10/10 - 0s - loss: 58.3713 - val_loss: 50.1762\n",
      "Epoch 28/100\n",
      "10/10 - 0s - loss: 57.3593 - val_loss: 45.6015\n",
      "Epoch 29/100\n",
      "10/10 - 0s - loss: 54.7388 - val_loss: 44.6998\n",
      "Epoch 30/100\n",
      "10/10 - 0s - loss: 55.0977 - val_loss: 43.7709\n",
      "Epoch 31/100\n",
      "10/10 - 0s - loss: 53.1282 - val_loss: 42.9339\n",
      "Epoch 32/100\n",
      "10/10 - 0s - loss: 51.9246 - val_loss: 47.9553\n",
      "Epoch 33/100\n",
      "10/10 - 0s - loss: 52.1127 - val_loss: 44.8335\n",
      "Epoch 34/100\n",
      "10/10 - 0s - loss: 52.6595 - val_loss: 44.6202\n",
      "Epoch 35/100\n",
      "10/10 - 0s - loss: 52.9229 - val_loss: 41.8737\n",
      "Epoch 36/100\n",
      "10/10 - 0s - loss: 49.5019 - val_loss: 41.1037\n",
      "Epoch 37/100\n",
      "10/10 - 0s - loss: 48.8460 - val_loss: 40.8510\n",
      "Epoch 38/100\n",
      "10/10 - 0s - loss: 50.2651 - val_loss: 40.0811\n",
      "Epoch 39/100\n",
      "10/10 - 0s - loss: 50.8488 - val_loss: 40.4763\n",
      "Epoch 40/100\n",
      "10/10 - 0s - loss: 49.7253 - val_loss: 39.6521\n",
      "Epoch 41/100\n",
      "10/10 - 0s - loss: 46.6606 - val_loss: 41.3749\n",
      "Epoch 42/100\n",
      "10/10 - 0s - loss: 48.9371 - val_loss: 37.0938\n",
      "Epoch 43/100\n",
      "10/10 - 0s - loss: 46.0442 - val_loss: 33.5186\n",
      "Epoch 44/100\n",
      "10/10 - 0s - loss: 41.8975 - val_loss: 30.9017\n",
      "Epoch 45/100\n",
      "10/10 - 0s - loss: 36.9610 - val_loss: 29.6497\n",
      "Epoch 46/100\n",
      "10/10 - 0s - loss: 36.2064 - val_loss: 29.0329\n",
      "Epoch 47/100\n",
      "10/10 - 0s - loss: 35.3415 - val_loss: 33.0369\n",
      "Epoch 48/100\n",
      "10/10 - 0s - loss: 34.1600 - val_loss: 27.7058\n",
      "Epoch 49/100\n",
      "10/10 - 0s - loss: 34.2711 - val_loss: 26.6262\n",
      "Epoch 50/100\n",
      "10/10 - 0s - loss: 38.4122 - val_loss: 30.5834\n",
      "Epoch 51/100\n",
      "10/10 - 0s - loss: 33.9845 - val_loss: 25.7930\n",
      "Epoch 52/100\n",
      "10/10 - 0s - loss: 30.7688 - val_loss: 26.2072\n",
      "Epoch 53/100\n",
      "10/10 - 0s - loss: 30.9479 - val_loss: 36.1149\n",
      "Epoch 54/100\n",
      "10/10 - 0s - loss: 33.0610 - val_loss: 25.0460\n",
      "Epoch 55/100\n",
      "10/10 - 0s - loss: 30.3625 - val_loss: 24.2672\n",
      "Epoch 56/100\n",
      "10/10 - 0s - loss: 29.9041 - val_loss: 24.5428\n",
      "Epoch 57/100\n",
      "10/10 - 0s - loss: 28.7848 - val_loss: 25.2176\n",
      "Epoch 58/100\n",
      "10/10 - 0s - loss: 29.9576 - val_loss: 27.5877\n",
      "Epoch 59/100\n",
      "10/10 - 0s - loss: 28.4578 - val_loss: 23.5401\n",
      "Epoch 60/100\n",
      "10/10 - 0s - loss: 27.8350 - val_loss: 23.7133\n",
      "Epoch 61/100\n",
      "10/10 - 0s - loss: 27.4980 - val_loss: 22.5369\n",
      "Epoch 62/100\n",
      "10/10 - 0s - loss: 27.3195 - val_loss: 23.0051\n",
      "Epoch 63/100\n",
      "10/10 - 0s - loss: 27.1850 - val_loss: 21.7432\n",
      "Epoch 64/100\n",
      "10/10 - 0s - loss: 26.9779 - val_loss: 25.2609\n",
      "Epoch 65/100\n",
      "10/10 - 0s - loss: 29.1319 - val_loss: 24.9964\n",
      "Epoch 66/100\n",
      "10/10 - 0s - loss: 27.2471 - val_loss: 20.5216\n",
      "Epoch 67/100\n",
      "10/10 - 0s - loss: 26.5363 - val_loss: 20.8333\n",
      "Epoch 68/100\n",
      "10/10 - 0s - loss: 27.1183 - val_loss: 20.6011\n",
      "Epoch 69/100\n",
      "10/10 - 0s - loss: 29.6362 - val_loss: 21.3842\n",
      "Epoch 70/100\n",
      "10/10 - 0s - loss: 25.1444 - val_loss: 21.1520\n",
      "Epoch 71/100\n",
      "10/10 - 0s - loss: 24.7653 - val_loss: 19.8922\n",
      "Epoch 72/100\n",
      "10/10 - 0s - loss: 24.1770 - val_loss: 21.4886\n",
      "Epoch 73/100\n",
      "10/10 - 0s - loss: 23.8079 - val_loss: 20.5175\n",
      "Epoch 74/100\n",
      "10/10 - 0s - loss: 24.4518 - val_loss: 19.8560\n",
      "Epoch 75/100\n",
      "10/10 - 0s - loss: 24.1856 - val_loss: 18.7094\n",
      "Epoch 76/100\n",
      "10/10 - 0s - loss: 23.8793 - val_loss: 19.0653\n",
      "Epoch 77/100\n",
      "10/10 - 0s - loss: 23.1785 - val_loss: 18.1416\n",
      "Epoch 78/100\n",
      "10/10 - 0s - loss: 22.3892 - val_loss: 18.9177\n",
      "Epoch 79/100\n",
      "10/10 - 0s - loss: 23.0814 - val_loss: 18.0571\n",
      "Epoch 80/100\n",
      "10/10 - 0s - loss: 22.7851 - val_loss: 18.8404\n",
      "Epoch 81/100\n",
      "10/10 - 0s - loss: 22.7444 - val_loss: 19.7663\n",
      "Epoch 82/100\n",
      "10/10 - 0s - loss: 22.6082 - val_loss: 16.5774\n",
      "Epoch 83/100\n",
      "10/10 - 0s - loss: 20.6009 - val_loss: 17.4726\n",
      "Epoch 84/100\n",
      "10/10 - 0s - loss: 22.6812 - val_loss: 20.7943\n",
      "Epoch 85/100\n",
      "10/10 - 0s - loss: 22.3556 - val_loss: 23.1957\n",
      "Epoch 86/100\n",
      "10/10 - 0s - loss: 23.9002 - val_loss: 20.1518\n",
      "Epoch 87/100\n",
      "10/10 - 0s - loss: 22.0096 - val_loss: 22.3773\n",
      "Epoch 00087: early stopping\n",
      "Final score (RMSE): 3.945493459701538\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1))   #  output layer\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Layer  (A dedicated layer for regularization)\n",
    "\n",
    "#### Each dropout layer will drop neurons in its previous layer.\n",
    "\n",
    "***To create a dropout layer, specify dropout probability.***  The dropout probability indicates the likelihood of a neuron dropping out for every batch during training. Typically this value is 0.1 to 0.5. \n",
    "\n",
    "***Actually, a certain percentage of neurons will be masked during each training iteration.  All neurons return after training is complete.*** \n",
    "\n",
    "\n",
    "Animation that shows how [dropout works](https://yusugomori.com/projects/deep-learning/dropout-relu)\n",
    "\n",
    "#### A dropout layer can be added between any two hidden layers to reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Code with Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369908/3165991113.py:24: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop('name',1,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin-1</th>\n",
       "      <th>origin-2</th>\n",
       "      <th>origin-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>4425</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>390.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3850</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>383.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>340.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3761</td>\n",
       "      <td>9.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2774</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0   18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1   15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2   18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3   16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4   17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5   15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6   14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7   14.0          8         440.0       215.0    4312           8.5    70   \n",
       "8   14.0          8         455.0       225.0    4425          10.0    70   \n",
       "9   15.0          8         390.0       190.0    3850           8.5    70   \n",
       "10  15.0          8         383.0       170.0    3563          10.0    70   \n",
       "11  14.0          8         340.0       160.0    3609           8.0    70   \n",
       "12  15.0          8         400.0       150.0    3761           9.5    70   \n",
       "13  14.0          8         455.0       225.0    3086          10.0    70   \n",
       "14  24.0          4         113.0        95.0    2372          15.0    70   \n",
       "15  22.0          6         198.0        95.0    2833          15.5    70   \n",
       "16  18.0          6         199.0        97.0    2774          15.5    70   \n",
       "17  21.0          6         200.0        85.0    2587          16.0    70   \n",
       "18  27.0          4          97.0        88.0    2130          14.5    70   \n",
       "19  26.0          4          97.0        46.0    1835          20.5    70   \n",
       "\n",
       "    origin-1  origin-2  origin-3  \n",
       "0          1         0         0  \n",
       "1          1         0         0  \n",
       "2          1         0         0  \n",
       "3          1         0         0  \n",
       "4          1         0         0  \n",
       "5          1         0         0  \n",
       "6          1         0         0  \n",
       "7          1         0         0  \n",
       "8          1         0         0  \n",
       "9          1         0         0  \n",
       "10         1         0         0  \n",
       "11         1         0         0  \n",
       "12         1         0         0  \n",
       "13         1         0         0  \n",
       "14         0         0         1  \n",
       "15         1         0         0  \n",
       "16         1         0         0  \n",
       "17         1         0         0  \n",
       "18         0         0         1  \n",
       "19         0         1         0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "# TensorFlow with Dropout for Regression\n",
    "############################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('name',1,inplace=True)\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = to_xy(df,\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 - 0s - loss: 254542.5312 - val_loss: 21280.7402\n",
      "Epoch 2/1000\n",
      "10/10 - 0s - loss: 16532.5254 - val_loss: 15670.0098\n",
      "Epoch 3/1000\n",
      "10/10 - 0s - loss: 9504.4922 - val_loss: 712.7132\n",
      "Epoch 4/1000\n",
      "10/10 - 0s - loss: 7526.7373 - val_loss: 652.9702\n",
      "Epoch 5/1000\n",
      "10/10 - 0s - loss: 6178.0259 - val_loss: 503.0488\n",
      "Epoch 6/1000\n",
      "10/10 - 0s - loss: 5332.0439 - val_loss: 385.2239\n",
      "Epoch 7/1000\n",
      "10/10 - 0s - loss: 4290.3291 - val_loss: 499.9599\n",
      "Epoch 8/1000\n",
      "10/10 - 0s - loss: 4418.4155 - val_loss: 612.4316\n",
      "Epoch 9/1000\n",
      "10/10 - 0s - loss: 4315.7339 - val_loss: 624.3520\n",
      "Epoch 10/1000\n",
      "10/10 - 0s - loss: 4775.9580 - val_loss: 1320.2142\n",
      "Epoch 11/1000\n",
      "10/10 - 0s - loss: 3467.8394 - val_loss: 2149.9863\n",
      "Epoch 00011: early stopping\n",
      "Final score (RMSE): 46.36794662475586\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,046\n",
      "Trainable params: 2,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection:  How 500 and 1275 were calcuated?\n",
    "\n",
    "1275 = 50*25 + 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
    "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
    "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
    "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
    "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
    "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
